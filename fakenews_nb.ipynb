{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Gxa4P8wvzMAT",
        "outputId": "22980c28-b0cf-4ad0-e5a4-ef8bbc8567da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Unnamed: 0                                              title  \\\n",
            "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
            "1           1                                                NaN   \n",
            "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
            "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
            "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
            "\n",
            "                                                text  label  \n",
            "0  No comment is expected from Barack Obama Membe...      1  \n",
            "1     Did they post their votes for Hillary already?      1  \n",
            "2   Now, most of the demonstrators gathered last ...      1  \n",
            "3  A dozen politically active pastors came here f...      0  \n",
            "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 72134 entries, 0 to 72133\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Unnamed: 0  72134 non-null  int64 \n",
            " 1   title       71576 non-null  object\n",
            " 2   text        72095 non-null  object\n",
            " 3   label       72134 non-null  int64 \n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 2.2+ MB\n",
            "None\n",
            "label\n",
            "1    37106\n",
            "0    35028\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">640,128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m640,128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">648,449</span> (2.47 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m648,449\u001b[0m (2.47 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">648,449</span> (2.47 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m648,449\u001b[0m (2.47 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.8671 - loss: 0.3261 - val_accuracy: 0.9544 - val_loss: 0.1265\n",
            "Epoch 2/6\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9680 - loss: 0.0932 - val_accuracy: 0.9563 - val_loss: 0.1283\n",
            "Epoch 3/6\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0555 - val_accuracy: 0.9590 - val_loss: 0.1344\n",
            "Epoch 4/6\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0372 - val_accuracy: 0.9591 - val_loss: 0.1486\n",
            "Epoch 5/6\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0249 - val_accuracy: 0.9586 - val_loss: 0.1738\n",
            "Epoch 6/6\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0189 - val_accuracy: 0.9603 - val_loss: 0.1779\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.1482\n",
            "Test Accuracy: 96.22%\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96      7089\n",
            "           1       0.96      0.97      0.96      7338\n",
            "\n",
            "    accuracy                           0.96     14427\n",
            "   macro avg       0.96      0.96      0.96     14427\n",
            "weighted avg       0.96      0.96      0.96     14427\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import classification_report\n",
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "path = input(\"Enter the path of the WELFake_Dataset.csv\")\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "\n",
        "\n",
        "df['combined_text'] = df['title'] + \" \" + df['text']\n",
        "df['combined_text'] = df['combined_text'].fillna('')\n",
        "\n",
        "# df = df.dropna(subset=['combined_text'])\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "df['cleaned_text'] = df['combined_text'].apply(clean_text)\n",
        "\n",
        "\n",
        "X = df['cleaned_text']\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "\n",
        "\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "\n",
        "def create_model():\n",
        "\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(X_train_tfidf.shape[1],)),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "    X_train_dense = X_train_tfidf.toarray()\n",
        "    X_test_dense = X_test_tfidf.toarray()\n",
        "\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_dense, y_train,\n",
        "        epochs=6,\n",
        "        batch_size=64,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    loss, accuracy = model.evaluate(X_test_dense, y_test)\n",
        "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    model.save(\"fakenews.h5\")\n",
        "    return X_train_dense, X_test_dense\n",
        "\n",
        "if not os.path.exists(\"fakenews.h5\"):\n",
        "    X_train_dense, X_test_dense = create_model()\n",
        "else:\n",
        "    model = load_model('fakenews.h5')\n",
        "\n",
        "y_pred = model.predict(X_test_dense)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "def predict_fake_news(text):\n",
        "    cleaned_text = clean_text(text)\n",
        "    text_tfidf = vectorizer.transform([cleaned_text])\n",
        "    text_dense = text_tfidf.toarray()\n",
        "    prediction = model.predict(text_dense)\n",
        "    confidence = prediction[0][0]\n",
        "    label = \"Fake\" if prediction > 0.5 else \"Real\"\n",
        "    return label, confidence\n",
        "\n",
        "#TEST\n",
        "# new_article = \"This is a fake news article designed to mislead people.\"\n",
        "# label, confidence = predict_fake_news(new_article)\n",
        "# print(f\"Prediction: {label} (Confidence: {confidence:.2f})\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7jfq7PUZlmD",
        "outputId": "0cbfcf94-5176-476b-f686-fbbcb6308c63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "If you would like to check text from copy-paste, enter 1 \n",
            "If you would like to check from a website link, enter 2.\n",
            "If you are done, press 0 to exit. 2\n",
            "Enter the website link here or press 0 to quit altogether: https://www.cnn.com/2025/02/21/politics/trump-fires-top-us-general-cq-brown/index.html\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "This is most likely real news\n",
            "If you would like to check text from copy-paste, enter 1 \n",
            "If you would like to check from a website link, enter 2.\n",
            "If you are done, press 0 to exit. 0\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_article_text(url):\n",
        "    \"\"\"Extracts and cleans main article text from a given URL.\"\"\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Try extracting main article content\n",
        "    article = soup.find(\"article\")\n",
        "    if article:\n",
        "        paragraphs = article.find_all(\"p\")\n",
        "    else:\n",
        "        # If no <article> tag is found, fallback to all <p> tags\n",
        "        paragraphs = soup.find_all(\"p\")\n",
        "\n",
        "    text = \" \".join(p.get_text() for p in paragraphs if p.get_text().strip())\n",
        "\n",
        "    return text if text else None  # Return None if no meaningful text is found\n",
        "\n",
        "while True:\n",
        "    x = input(\"If you would like to check text from copy-paste, enter 1 \\nIf you would like to check from a website link, enter 2.\\nIf you are done, press 0 to exit. \")\n",
        "\n",
        "    if x not in {\"1\", \"2\", \"0\"}:\n",
        "        print(\"Invalid input.\")\n",
        "        continue\n",
        "\n",
        "    if x == \"1\":\n",
        "        new_article = input(\"Enter your article here: \")\n",
        "        label, confidence = predict_fake_news(new_article)\n",
        "        confidence = math.ceil(confidence * 10**5) / 10**5\n",
        "        print(f\"This is most likely {label.lower()} news, and I am {confidence * 100}% sure.\")\n",
        "\n",
        "    elif x == \"2\":\n",
        "        url = input(\"Enter the website link here or press 0 to quit altogether: \")\n",
        "        if url == \"0\":\n",
        "            break\n",
        "\n",
        "        article_text = get_article_text(url)\n",
        "        if not article_text:\n",
        "            print(\"Could not extract meaningful text from the URL. Try another website.\")\n",
        "            continue\n",
        "\n",
        "        label, confidence = predict_fake_news(article_text)\n",
        "        confidence = math.ceil(confidence * 10**5) / 10**5\n",
        "        print(f\"This is most likely {label.lower()} news\")\n",
        "\n",
        "    elif x == \"0\":\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
